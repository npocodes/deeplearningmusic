# Music Multi Genre(Class) Training Script
# 
# Author: C-490 Deep Learning Group
#
# Brief: This file is aimed at classifying 8 music genres
#        using spectrograms generated by a custom program,
#        "audmage.py", from audio files in the FMA datasets.
# 
# Directory Structure: 
#     dataset/spect/{train, validate, test}/<genre>/<image.png>
#        .../audmage/...
#
# Command Options:
#     #1 - directory path to dataset ex: ('dataset/spectrograms')
#          the program will look here for train and validate dirs
#          and count files and classes automatically
#          
#     #2 - filename and path to save results file
#          ex: ('myresults/dlag.h5')
#
#     If no command options given, default values are used.
#
# ToDo: (
#        'Solve Model Saving Issue: https://github.com/keras-team/keras/issues/4875'
#        'Do more testing of saving the model/weights...'
#        'Try saving model structure etc.. as JSON or YAML file in lieu of H5'
#       )
##############################################################

#Imports
import matplotlib
matplotlib.use('AGG')#required for "headless" servers
import matplotlib.pyplot as plt
import keras
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense
from keras import backend as K
from keras.optimizers import SGD
import numpy as np
import sys
import os
#Model Saving Bug Fix
#from keras.backend import manual_variable_initialization 


#Default Command argument variable
dataPath = 'dataset/spect-med' #Directory containing (train and validate directories)
saveName = 'dlag-test2-med' #Name to use when saving model/results.

#Set Name
setName = 'Spectrogram Medium Set'

# The dimensions to which all images found will be resized.
#img_width, img_height = 252, 188 #Half size original
img_width, img_height = 503, 376 #Original size

#Epoch and batch variables
epochs = 50
batch_size = 16
#(Reduce batch size if OOM error)

#The rest of these are found or assumed
dataPathT = dataPath +"/train"    #Default training data path
dataPathV = dataPath +"/validate" #Default validation data path
dataPathP = dataPath +"/test"     #Default test(predict) data path
#Use: None value to skip predictions

trainCount = 7000  #Default training image count (Auto counted)
validCount = 800   #Default validation image count (Auto counted)
classCount = 8     #Default class count(found from train/valid sub-directories)

#Lets see the package versions for convenience
print "Keras Version:  "+ str(keras.__version__)
print "Numpy Version:  "+ str(np.__version__)
print "Matplotlib:     "+ str(matplotlib.__version__)
print "Python Version: "+ str(sys.version_info[:3][0]) +'.'+ str(sys.version_info[:3][1]) +'.'+ str(sys.version_info[:3][2])
print "\n"

#Begin setting up options and inputs #
#Do we have any commandline arguments?
if len(sys.argv) > 1:

  #1 - path to dataset (assuming it contains min: train, validate)
  if not os.path.isdir(sys.argv[1]) == True:
    print "Error, " + str(sys.argv[1]) +" is not a directory or doesn't exist\n"
    sys.exit()
  else:
    dataPath = str(sys.argv[1])
    #Finished with option 1 (data directory)
    
    if len(sys.argv) > 2:
      #We also were given a saveName/path for the results file
      saveName = str(sys.argv[2])
      
    if len(sys.argv) > 3:
      #And a name for the set being ran (for graphs)
      setName = str(sys.argv[3])
      
  #Finished setting up options
else:
  #No options given use defaults
  print "Using default options.."

print 'Results will be saved to: '+ saveName
print 'Running: '+ setName

#Verify that the directory given has {train, test, validate} dirs
subList = os.listdir(dataPath)
c = 0 #count of sub-dirs
cCountT = 0 #count of train classes
cCountV = 0 #count of validate classes
cCountP = 0 #count of test classes
for subDir in subList:
  subStr = str(subDir).lower()
  if subStr == 'train' or subStr == 'training':
    dataPathT = dataPath +'/'+ subStr
    for item in os.listdir(dataPathT):
      if os.path.isdir(dataPathT +'/'+ item):
        cCountT += 1
    fCount = sum([len(files) for r, d, files in os.walk(dataPathT)])
    print 'Found training directory: '+ dataPathT
    print 'Found '+ str(cCountT) +' training classes.'
    print 'Found '+ str(fCount) +' training images.\n'
    c += 1
  elif subStr == 'validate' or subStr == 'validation':
    dataPathV = dataPath +'/'+ subStr
    for item in os.listdir(dataPathV):
      if os.path.isdir(dataPathV +'/'+ item):
        cCountV += 1
    fCount = sum([len(files) for r, d, files in os.walk(dataPathV)])
    print 'Found validation directory: '+ dataPathV
    print 'Found '+ str(cCountV) +' validation classes.'
    print 'Found '+ str(fCount) +' validation images.\n'
    c += 1
  elif subStr == 'test' or subStr == 'predict':
    dataPathP = dataPath +'/'+ subStr
    for item in os.listdir(dataPathP):
      if os.path.isdir(dataPathP +'/'+ item):
        cCountP += 1
    fCount = sum([len(files) for r, d, files in os.walk(dataPathP)])
    print 'Found Test(Prediction) directory: '+ dataPathP
    print 'Found '+ str(cCountP) +' test classes.'
    print 'Found '+ str(fCount) +' test images.\n'
    c += 1      
  else:
    if c >= 3:
      break #We found them, stop looking.
#END subDir loop
if not c >= 2:
  print 'Unable to locate both train and validation directories.'
  sys.exit()
if not cCountV == cCountT:
  print 'Train and Validation have different number of classes.'
  sys.exit()

#Verify input_shape format
if K.image_data_format() == 'channels_first':
    input_shape = (3, img_width, img_height)
else:
    input_shape = (img_width, img_height, 3)

#Begin our model
model = Sequential()

#Add 1st convolutional layer
model.add(Conv2D(
  filters=32, #the # of output filters 
  kernel_size=(3, 3), #mask size
  input_shape=input_shape, #resized dimensions of our images
  activation='relu'))

#Add 1st pooling layer
model.add(MaxPooling2D(pool_size=(2, 2))) #halve the input in both spatial dimensions

#Add 2nd convolutional layer
model.add(Conv2D(
  filters=32, #the # of output filters 
  kernel_size=(3, 3), #mask size
  #Don't have to give input size again
  activation='relu'))

#Add 2nd pooling layer
model.add(MaxPooling2D(pool_size=(2, 2))) #halve the input in both spatial dimensions

#Add 3rd convolutional layer
model.add(Conv2D(
  filters=64, #the # of output filters 
  kernel_size=(3, 3), #mask size
  #Don't have to give input size again
  activation='relu'))

#Add 3rd pooling layer
model.add(MaxPooling2D(pool_size=(2, 2))) #halve the input in both spatial dimensions

#Add 1st flatten layer
model.add(Flatten()) #Flattens input to single dim 

#Add 1st Dense layer
model.add(Dense(
  units=64, #Dimension for output space 
  input_dim=input_shape, #resized dimensions of our images
  activation='relu'))

#Add 1st DropOut Layer
#randomly set a fraction rate of 0.5 to 0 at each update during 
#training time, which helps prevent overfitting.
model.add(Dropout(0.5))

#Add 2nd Dense layer
model.add(Dense(
  units=classCount, #Dimension for output space 
  #Don't need to specify size again
  activation='softmax')) #switch to a softmax activation


#Finally, configure the model for training.
model.compile(loss='categorical_crossentropy', #Loss function
              optimizer=SGD(lr=1e-2, momentum=0.9), #Optimizer function
              metrics=['accuracy']) #measurements evaluated by the model

# this is the augmentation configuration we will use for training
train_datagen = ImageDataGenerator(
    rescale=1. / 255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True)

# this is the augmentation configuration we will use for testing:
# only rescaling
validate_datagen = ImageDataGenerator(rescale=1. / 255)

#Create a training generator that will load our image files
#and create augmented versions of them to train on.
train_generator = train_datagen.flow_from_directory(
    dataPathT,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='categorical')

#Create a validation generator that will do the same but
#for validation segment of the script
validation_generator = validate_datagen.flow_from_directory(
    dataPathV,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='categorical')

##################################################
## BEGIN ACTUAL TRAINING and VALIDATION PROCESS ##
##################################################
#Begin fitting the model (and generating aug. images)
history = model.fit_generator(
    train_generator,
    steps_per_epoch=trainCount // batch_size,
    epochs=epochs,
    validation_data=validation_generator,
    validation_steps=validCount // batch_size,
    use_multiprocessing=False, workers=1)

## BEGIN TROUBLE ZONE ##

#Saving the model isn't working properly.
#If just weights are saved, and then loaded into exact same
#model architecture (no training) predictions are like
#the model has never been trained (all junk)
print model.summary()
print '\n'
model.save_weights(saveName+"_weights.h5")
print 'Model weights have been saved.'
print model.summary()

#If the whole model is saved, the same problem
#occurs when reloaded. And current session predictions are junk.
model.save(saveName+".h5")#Save the whole model
print 'Full model has been saved.'
print model.summary()

#so far the model summary() doesn't change
#current save configuration (save_weights, then model.save())
#seems to work. The current sessions prediction look accurate.
#have not attempted yet to load in and do predictions.

## LEAVING TROUBLE ZONE ##

#######################
## BEGIN PREDICTIONS ##
#######################
if not dataPathP == None:
  print 'Model has been trained and saved.\nBeginning Predictions: using \'test\' directory.'
  
  #Initiate an ImageDataGenerator
  prediction_datagen = ImageDataGenerator()

  #Load the ImageDataGenerator with images from our test directory
  prediction_generator = prediction_datagen.flow_from_directory(
    dataPathP, #Path to the test directory
    target_size=(img_width, img_height), #resized dimensions of our images
    batch_size=batch_size, #Provide the batch size to use
    classes=['Electronic', 'Experimental', 'Folk', 'Hip-Hop', 'Instrumental', 'International', 'Pop', 'Rock'],
    class_mode='categorical')#Pass the labels into the generator, and switch mode to categorical

  #Let's make our predictions!!
  final_predictions = model.predict_generator(
    prediction_generator, #pass in our ImageDataGenerator Results
    verbose=True, #Show us that your doing something.
    use_multiprocessing=False, #Use built in multi-processing.
    workers=1)  #Set how many sub-processes you want.

  #Get the class index dictionary and filenames
  classIndexDict = prediction_generator.class_indices #Dictionary of Class -> Index
  fileNameIndex = prediction_generator.filenames      #Matching filenames to predictions output

  print "Saving our test predictions to "+ saveName +".txt"
  #Let's save our predictions in a readable manner
    #FILENAME.PNG P1 P2 P3 P4 P5 P6 P7 P8
    #FILENAME2.PNG
  pred_file = open(saveName+'.txt', 'a')

  #Round to 3 decimal places so its easier to understand the data at a glance
  np.set_printoptions(precision=4, suppress=True)#change print precision and suppress small values (e-78 etc..)
  p_predictions = np.round(final_predictions*100, decimals=4)#convert to percentage
  p_string = '' #prediction string holder
  print >> pred_file, "    TrackName      Electronic      Experimental      Folk      Hip-Hop     Instrumental      International     Pop     Rock"
  n = 0 #predictionList / filename index
  while n < len(p_predictions):
    p_string = ''#prediction string holder
    p = 0 #prediction element index
    while p < len(p_predictions[n]):
      p_string += ' '+str(p_predictions[n][p])
      p += 1 #Go to next prediction element
    #END prediction element loop
    print >> pred_file, str(fileNameIndex[n]) +" "+ p_string
    n += 1 #Go to next prediction list/filename
  #END prediction list loop
  pred_file.close()

print 'Saving the Train and Validation graphs'
#############################
# TRAIN & VALIDATION GRAPHS #
#############################
history.history.keys()
H = history.history
#  "Accuracy"
plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('Model Accuracy - '+ setName)
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.ylim(0, 1)
plt.xlim(0, 50)
plt.legend(['Train', 'Validation'], loc='upper left')
plt.savefig("accuracy.jpg")

# "Loss"
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss - '+ setName)
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.ylim(0, 5)
plt.xlim(0, 50)
plt.legend(['Train', 'Validation'], loc='upper left')
plt.savefig("loss.jpg")

#combined
N = np.arange(0, len(history.history["loss"]))
plt.style.use("ggplot")
plt.figure()
plt.plot(N, history.history["loss"], label="train_loss")
plt.plot(N, H["val_loss"], label="test_loss")
plt.plot(N, H["acc"], label="train_acc")
plt.plot(N, H["val_acc"], label="test_acc")
plt.title("Accuracy and Loss - "+ setName)
plt.xlabel("Epoch #")
plt.ylabel("Loss/Accuracy")
plt.legend()
 
# save the figure
plt.savefig("lossaccuracy.jpg")

