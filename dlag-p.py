# Music Multi Genre(Class) Training Script
# 
# Author: C-490 Deep Learning Group
#
# Brief: This file is a modified version of the script
#        written by fchollet for the keras cats/dogs blog.
#        This version is aimed at classifying 8 music genres
#        using spectrograms generated by a custom program,
#        "audmage.py", from audio files in the FMA datasets.
# 
# Directory Structure: 
#     dataset/spect/{train, validate, test}/<genre>/<image.png>
#        .../audmage/...
#
# Command Options:
#     #1 - directory path to dataset ex: ('dataset/spectrograms')
#          the program will look here for train and validate dirs
#          and count files and classes automatically
#          
#     #2 - filename and path to save results file
#          ex: ('myresults/dlag.h5')
#
#     If no command options given, default values are used.
#
# ToDo: (
#        'run spect-med w/default values',
#        'run aud-med w/default values',
#        'Associate Prediction Results with file names/paths'
#       )
##############################################################

#Imports
import matplotlib
matplotlib.use('AGG')
import matplotlib.pyplot as plt
import keras
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense
from keras import backend as K
from keras.optimizers import SGD
import numpy as np
import sys
import os


#Default Command argument variable
dataPath = 'dataset/spect' #Directory containing (train and validate directories)
saveName = 'dlag.h5' #Name to use when saving model/results.

#Set Name
setName = 'Spectrogram Med Set'

# The dimensions to which all images found will be resized.
img_width, img_height = 503, 376 #Original values

#Epoch and batch variables
epochs = 1
batch_size = 16
#(Reduce batch size if OOM error)

#The rest of these are found or assumed
dataPathT = dataPath +"/train"    #Default training data path
dataPathV = dataPath +"/validate" #Default validation data path
dataPathP = None                  #Default test(predict) data path
  #dataPath +"/test"

trainCount = 6396 #Default training image count (Auto counted)
validCount = 800  #Default validation image count (Auto counted)
classCount = 8    #Default class count(found from train/valid sub-directories)

#Lets see the keras version for convenience
print "Keras Version: "+ str(keras.__version__)

#Begin setting up options and inputs #
#Do we have any commandline arguments?
if len(sys.argv) > 1:

  #1 - path to dataset (assuming it contains min: train, validate)
  if not os.path.isdir(sys.argv[1]) == True:
    print "Error, " + str(sys.argv[1]) +" is not a directory or doesn't exist\n"
    sys.exit()
  else:
    dataPath = str(sys.argv[1])
    #Verify that the directory given has {train, test, validate} dirs
    subList = os.listdir(dataPath)
    c = 0 #count of sub-dirs
    cCountT = 0 #count of train classes
    cCountV = 0 #count of validate classes
    cCountP = 0 #count of test classes
    for subDir in subList:
      subStr = str(subDir).lower()
      if subStr == 'train' or subStr == 'training':
        dataPathT = dataPath +'/'+ subStr
        for item in os.listdir(dataPathT):
          if os.path.isdir(dataPathT +'/'+ item):
            cCountT += 1
        fCount = sum([len(files) for r, d, files in os.walk(dataPathT)])
        print 'Found training directory: '+ dataPathT
        print 'Found '+ str(cCountT) +' training classes.'
        print 'Found '+ str(fCount) +' training images.\n'
        c += 1
      elif subStr == 'validate' or subStr == 'validation':
        dataPathV = dataPath +'/'+ subStr
        for item in os.listdir(dataPathV):
          if os.path.isdir(dataPathV +'/'+ item):
            cCountV += 1
        fCount = sum([len(files) for r, d, files in os.walk(dataPathV)])
        print 'Found validation directory: '+ dataPathV
        print 'Found '+ str(cCountV) +' validation classes.'
        print 'Found '+ str(fCount) +' validation images.\n'
        c += 1
      elif subStr == 'test' or subStr == 'predict':
        dataPathP = dataPath +'/'+ subStr
        for item in os.listdir(dataPathP):
          if os.path.isdir(dataPathP +'/'+ item):
            cCountP += 1
        fCount = sum([len(files) for r, d, files in os.walk(dataPathP)])
        print 'Found Test(Prediction) directory: '+ dataPathP
        print 'Found '+ str(cCountP) +' test classes.'
        print 'Found '+ str(fCount) +' test images.\n'
        c += 1      
      else:
        if c >= 3:
          break #We found them, stop looking.
    #END subDir loop
    if not c >= 2:
      print 'Unable to locate both train and validation directories.'
      sys.exit()
    if not cCountV == cCountT:
      print 'Train and Validation have different number of classes.'
      sys.exit()
    #Finished with option 1 (data directory)
    
    if len(sys.argv) > 2:
      #We also were given a saveName/path for the results file
      saveName = sys.argv[2]
      print 'Results will be saved to: '+ saveName
  #Finished setting up options

#else:
  #No options given use defaults

#Verify input_shape format
if K.image_data_format() == 'channels_first':
    input_shape = (3, img_width, img_height)
else:
    input_shape = (img_width, img_height, 3)

#Begin our model
model = Sequential()

#Add 1st convolutional layer
model.add(Conv2D(
  filters=32, #the # of output filters 
  kernel_size=(3, 3), #mask size
  input_shape=input_shape, #resized dimensions of our images
  activation='relu'))

#Add 1st pooling layer
model.add(MaxPooling2D(pool_size=(2, 2))) #halve the input in both spatial dimensions

#Add 2nd convolutional layer
model.add(Conv2D(
  filters=32, #the # of output filters 
  kernel_size=(3, 3), #mask size
  #Don't have to give input size again
  activation='relu'))

#Add 2nd pooling layer
model.add(MaxPooling2D(pool_size=(2, 2))) #halve the input in both spatial dimensions


#Add 3rd convolutional layer
model.add(Conv2D(
  filters=64, #the # of output filters 
  kernel_size=(3, 3), #mask size
  #Don't have to give input size again
  activation='relu'))

#Add 3rd pooling layer
model.add(MaxPooling2D(pool_size=(2, 2))) #halve the input in both spatial dimensions

#Add 1st flatten layer
model.add(Flatten()) #Flattens input to single dim 

#Add 1st Dense layer
model.add(Dense(
  units=64, #Dimension for output space 
  input_dim=input_shape, #resized dimensions of our images
  activation='relu'))

#Add 1st DropOut Layer
#randomly set a fraction rate of 0.5 to 0 at each update during 
#training time, which helps prevent overfitting.
model.add(Dropout(0.5))

#Add 2nd Dense layer
model.add(Dense(
  units=classCount, #Dimension for output space 
  #Don't need to specify size again
  activation='softmax')) #switch to a softmax activation


#Finally, configure the model for training.
model.compile(loss='categorical_crossentropy', #Loss function
              optimizer=SGD(lr=1e-2, momentum=0.9), #Optimizer function
              metrics=['accuracy']) #measurements evaluated by the model

# this is the augmentation configuration we will use for training
train_datagen = ImageDataGenerator(
    rescale=1. / 255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True)

# this is the augmentation configuration we will use for testing:
# only rescaling
validate_datagen = ImageDataGenerator(rescale=1. / 255)

#Create a training generator that will load our image files
#and create augmented versions of them to train on.
train_generator = train_datagen.flow_from_directory(
    dataPathT,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='categorical')

#Create a validation generator that will do the same but
#for validation segment of the script
validation_generator = validate_datagen.flow_from_directory(
    dataPathV,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='categorical')

#Begin fitting the model (and generating aug. images)
history = model.fit_generator(
    train_generator,
    steps_per_epoch=trainCount // batch_size,
    epochs=epochs,
    validation_data=validation_generator,
    validation_steps=validCount // batch_size,
    use_multiprocessing=True, workers=6)

#Save the weight parameters and values we learned.
model.save_weights(saveName)

#######################
## BEGIN PREDICTIONS ##
#######################
if not dataPathP == None:
  print 'Model has been trained and saved.\nBeginning Predictions: using \'test\' directory.'
  
  #Initiate an ImageDataGenerator
  prediction_datagen = ImageDataGenerator()

  #Load the ImageDataGenerator with images from our test directory
  prediction_generator = prediction_datagen.flow_from_directory(
    dataPathP, #Path to the test directory
    target_size=(img_width, img_height), #resized dimensions of our images
    batch_size=batch_size, #Provide the batch size to use
    classes=['Electronic', 'Experimental', 'Folk', 'Hip-Hop', 'Instrumental', 'International', 'Pop', 'Rock'],
    class_mode='categorical')#Pass the labels into the generator, and switch mode to categorical

  #Let's make our predictions!!
  final_predictions = model.predict_generator(
    prediction_generator, #pass in our ImageDataGenerator Results
    verbose=True, #Show us that your doing something.
    use_multiprocessing=True, #Use built in multi-processing.
    workers=6)  #Set how many sub-processes you want.

  #What to do with them now???
  print final_predictions
  print final_predictions.shape
  print 'Length of row[0]: '+ str(len(final_predictions[0]))

  #Print out the class-to-index dictionary.
  classIndexDict = prediction_generator.class_indices
  FileNameIndex = prediction_generator.filenames

  print 'Class->Index Dictionary:'
  print classIndexDict

  #print 'Filename Index: '
  #print FileNameIndex


#############################
# TRAIN & VALIDATION GRAPHS #
#############################
history.history.keys()
H = history.history
#  "Accuracy"
plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('Model Accuracy - '+ setName)
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.savefig("accuracy.jpg")

# "Loss"
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss - '+ setName)
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.savefig("loss.jpg")

#combined
N = np.arange(0, len(history.history["loss"]))
plt.style.use("ggplot")
plt.figure()
plt.plot(N, history.history["loss"], label="train_loss")
plt.plot(N, H["val_loss"], label="test_loss")
plt.plot(N, H["acc"], label="train_acc")
plt.plot(N, H["val_acc"], label="test_acc")
plt.title("Accuracy and Loss - "+ setName)
plt.xlabel("Epoch #")
plt.ylabel("Loss/Accuracy")
plt.legend()
 
# save the figure
plt.savefig("lossaccuracy.jpg")

